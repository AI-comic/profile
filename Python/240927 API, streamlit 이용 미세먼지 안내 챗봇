import streamlit as st
import json
import requests
from langchain_community.vectorstores import FAISS
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain.schema import Document
from langchain.embeddings.sentence_transformer import SentenceTransformerEmbeddings
from langchain_community.chat_models import ChatOllama
from langchain.prompts import ChatPromptTemplate
from langchain.schema.runnable import RunnableMap

# ëŒ€ê¸°ì§ˆ ë°ì´í„° ì¡°íšŒ í•¨ìˆ˜
def get_air_quality_data(sido):
    url = 'http://apis.data.go.kr/B552584/ArpltnInforInqireSvc/getCtprvnRltmMesureDnsty'
    params = {
        'serviceKey': 'ë³¸ì¸ í‚¤ë¥¼ ì…ë ¥í•˜ëŠ” ê³µê°„', 
        'returnType': 'json', 
        'numOfRows': '100', 
        'pageNo': '1', 
        'sidoName': sido, 
        'ver': '1.0'
    }
    response = requests.get(url, params=params)
    content = response.content.decode('utf-8')
    data = json.loads(content)
    return data

# ëŒ€ê¸°ì§ˆ ë°ì´í„° íŒŒì‹± í•¨ìˆ˜
def parse_air_quality_data(data):
    items = data['response']['body']['items']
    air_quality_info = []
    for item in items:
        info = {
            'ì¸¡ì •ì†Œëª…': item.get('stationName'),
            'ë‚ ì§œ': item.get('dataTime'),
            'ë¯¸ì„¸ë¨¼ì§€ë†ë„': item.get('pm10Value'),
            'ì´ˆë¯¸ì„¸ë¨¼ì§€ë†ë„': item.get('pm25Value'),
            'so2ë†ë„': item.get('so2Value'),
            'coë†ë„': item.get('coValue'),
            'o3ë†ë„': item.get('o3Value'),
            'no2ë†ë„': item.get('no2Value'),
            'í†µí•©ëŒ€ê¸°í™˜ê²½ìˆ˜ì¹˜': item.get('khaiValue'),
            'í†µí•©ëŒ€ê¸°í™˜ê²½ì§€ìˆ˜': item.get('khaiGrade'),
            'ë¯¸ì„¸ë¨¼ì§€ë“±ê¸‰': item.get('pm10Grade'),
            'ì´ˆë¯¸ì„¸ë¨¼ì§€ë“±ê¸‰': item.get('pm25Grade')
        }
        air_quality_info.append(info)
    return air_quality_info

# ë©”ì¸ ìŠ¤íŠ¸ë¦¼ë¦¿ ì•±
def main():
    st.set_page_config(page_title="ëŒ€ê¸°ì§ˆ ì •ë³´ ì±—ë´‡", layout="wide")
    st.title("ğŸŒ ëŒ€ê¸°ì§ˆ ì •ë³´ ì œê³µ ì±—ë´‡")
    st.markdown("""
    **ì•ˆë…•í•˜ì„¸ìš”!**  
    ëŒ€ê¸°ì§ˆ ì •ë³´ë¥¼ í™•ì¸í•˜ê³  ì‹¶ìœ¼ì‹  ì§€ì—­ì˜ ì´ë¦„ì„ ì…ë ¥í•´ ì£¼ì„¸ìš”.  
    ì •í™•í•œ ì •ë³´ë¥¼ ì œê³µí•˜ê¸° ìœ„í•´ ë¯¸ì„¸ë¨¼ì§€ ë†ë„ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë¶„ì„í•©ë‹ˆë‹¤.
    """)

    # ì‚¬ìš©ì ì…ë ¥
    sido = st.text_input("ğŸ“ ë„ì‹œ ì´ë¦„ì„ ì…ë ¥í•˜ì„¸ìš”:", "ì„œìš¸", max_chars=10)
    query = st.text_input("â“ ê¶ê¸ˆí•œ ì§€ì—­ì„ ì…ë ¥í•˜ì„¸ìš”:", "ìš©ì‚°êµ¬", max_chars=10)
    
    if st.button("ì§€ì—­ ì„ íƒ"):
        data = get_air_quality_data(sido)
        air_quality_info = parse_air_quality_data(data)

        documents = [
            Document(page_content=", ".join([f"{key}: {str(info[key])}" for key in ['ì¸¡ì •ì†Œëª…', 'ë‚ ì§œ', 'ë¯¸ì„¸ë¨¼ì§€ë†ë„', 'ì´ˆë¯¸ì„¸ë¨¼ì§€ë†ë„', 'í†µí•©ëŒ€ê¸°í™˜ê²½ìˆ˜ì¹˜']])) 
            for info in air_quality_info
        ]

        text_splitter = RecursiveCharacterTextSplitter(separators=",")
        docs = text_splitter.split_documents(documents)

        embedding_function = SentenceTransformerEmbeddings(model_name="jhgan/ko-sroberta-multitask")

        db = FAISS.from_documents(docs, embedding_function)
        retriever = db.as_retriever(search_type="similarity", search_kwargs={'k': 5, 'fetch_k': 100})
               
        if query:
            query_result = db.similarity_search(query)
            st.write("**DB ê²€ìƒ‰ ê²°ê³¼:**", query_result[0].page_content)

            # ì±—ë´‡ ì„¤ì •
            llm = ChatOllama(model="gemma2:9b", temperature=0.3)

            template = """
            ë‹¹ì‹ ì€ ëŒ€ê¸°ì§ˆì„ ì•ˆë‚´í•˜ëŠ” ì±—ë´‡ì…ë‹ˆë‹¤. 
            ì‚¬ìš©ìì—ê²Œ ê°€ëŠ¥í•œ ë§ì€ ì •ë³´ë¥¼ ì¹œì ˆí•˜ê²Œ ì œê³µí•˜ì‹­ì‹œì˜¤.            
            ë‹¤ìŒì˜ ê¸°ì¤€ìœ¼ë¡œ, ê³µê¸°ê°€ ì¢‹ìŒ, ë³´í†µ, ë‚˜ì¨, ë§¤ìš° ë‚˜ì¨ì„ íŒë³„í•´ì£¼ì„¸ìš”. 
            
            PM10 (ë¯¸ì„¸ë¨¼ì§€ ë†ë„)
                ì¢‹ìŒ: 0 ~ 30 
                ë³´í†µ: 31 ~ 80
                ë‚˜ì¨: 81 ~ 150 
                ë§¤ìš° ë‚˜ì¨: 151 ì´ìƒ
            PM2.5 (ì´ˆë¯¸ì„¸ë¨¼ì§€ ë†ë„)
                ì¢‹ìŒ: 0 ~ 15 
                ë³´í†µ: 16 ~ 35 
                ë‚˜ì¨: 36 ~ 75 
                ë§¤ìš° ë‚˜ì¨: 76 ì´ìƒ
            
            Answer the question as based only on the following context:
            {context}

            Question: {question}
            """
            prompt = ChatPromptTemplate.from_template(template)

            chain = RunnableMap({
                "context": lambda x: retriever.get_relevant_documents(x['question']),
                "question": lambda x: x['question']
            }) | prompt | llm

            question = query
            if question:
                response = chain.invoke({'question': question})
                st.markdown("**ì±—ë´‡ì˜ ë‹µë³€:**")
                st.markdown(response.content)

if __name__ == "__main__":
    main()
