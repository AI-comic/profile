import streamlit as st
import json
import requests
from langchain_community.vectorstores import FAISS
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain.schema import Document
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_ollama import ChatOllama
from langchain.prompts import ChatPromptTemplate
from langchain.schema.runnable import RunnableMap

# íƒ„ì†Œë°°ì¶œê¶Œ ë°ì´í„° ì¡°íšŒ í•¨ìˆ˜
def get_carbon_credit_data():
    url = 'http://apis.data.go.kr/1160100/service/GetGeneralProductInfoService/getCertifiedEmissionReductionPriceInfo'
    params = {
        'serviceKey': '~~~í‚¤ ì…ë ¥ ê³µê°„~~~',
        'resultType': 'json',
        'numOfRows': '100',
        'pageNo': '1',
    }
    try:
        response = requests.get(url, params=params)
        content = response.content.decode('utf-8')
        data = json.loads(content)
        return data
    except Exception as e:
        st.error(f"ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
        return None

# íƒ„ì†Œë°°ì¶œê¶Œ ë°ì´í„° íŒŒì‹± í•¨ìˆ˜
def parse_carbon_credit_data(data):
    items = data['response']['body']['items']['item']
    carbon_credit_info = []
    for item in items:
        info = {
            'ê¸°ì¤€ì¼ì': item.get('basDt'),
            'ë‹¨ì¶•ì½”ë“œ': item.get('srtnCd'),
            'ISINì½”ë“œ': item.get('isinCd'),
            'ì¢…ëª©ëª…': item.get('itmsNm'),
            'ì¢…ê°€': item.get('clpr'),
            'ëŒ€ë¹„': item.get('vs'),
            'ë“±ë½ë¥ ': item.get('fltRt'),
            'ê±°ë˜ëŸ‰': item.get('trqu'),
            'ê±°ë˜ëŒ€ê¸ˆ': item.get('trPrc'),
            'ìµœê³ ê°€': item.get('hipr'),
            'ìµœì €ê°€': item.get('lopr'),
            'ì‹œì‘ê°€': item.get('mkp'),
        }
        carbon_credit_info.append(info)
    return carbon_credit_info

# ë©”ì¸ ìŠ¤íŠ¸ë¦¼ë¦¿ ì•±
def main():
    st.set_page_config(page_title="íƒ„ì†Œë°°ì¶œê¶Œ ì •ë³´ ì±—ë´‡", layout="wide")
    st.title("ğŸŒ íƒ„ì†Œë°°ì¶œê¶Œ ì •ë³´ ì œê³µ ì±—ë´‡")
    st.markdown("""**ì•ˆë…•í•˜ì„¸ìš”!**
                í™•ì¸í•˜ê³  ì‹¶ì€ íƒ„ì†Œë°°ì¶œê¶Œ ì •ë³´ë¥¼ ì…ë ¥í•´ ì£¼ì„¸ìš”.""")

    query = st.text_input("ë¬´ì—‡ì´ ê¶ê¸ˆí•˜ì„¸ìš”â“", max_chars=50)

    if st.button("ì •ë³´ ì¡°íšŒ"):
        data = get_carbon_credit_data()
        if data:
            carbon_credit_info = parse_carbon_credit_data(data)

            documents = [
                Document(page_content=", ".join([f"{key}: {str(info[key])}" for key in ['ë‹¨ì¶•ì½”ë“œ', 'ê¸°ì¤€ì¼ì', 'ì¢…ëª©ëª…', 'ì¢…ê°€', 'ê±°ë˜ëŸ‰', 'ê±°ë˜ëŒ€ê¸ˆ', 'ë“±ë½ë¥ ', 'ëŒ€ë¹„', 'ìµœê³ ê°€', 'ìµœì €ê°€', 'ì‹œì‘ê°€']])) 
                for info in carbon_credit_info
            ]

            text_splitter = RecursiveCharacterTextSplitter(separators=",")
            docs = text_splitter.split_documents(documents)

            embedding_function = HuggingFaceEmbeddings(model_name="jhgan/ko-sroberta-multitask")

            db = FAISS.from_documents(docs, embedding_function)
            retriever = db.as_retriever(search_type="similarity", search_kwargs={'k': 5, 'fetch_k': 100})

            if query:
                query_result = retriever.get_relevant_documents(query)
                if query_result:
                    st.write("**DB ê²€ìƒ‰ ê²°ê³¼:**")
                    for result in query_result:
                        st.write(result.page_content)
                else:
                    st.write("ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")

                # ì±—ë´‡ ì„¤ì •
                llm = ChatOllama(model="gemma2:9b", temperature=0.3)

                template = """
                ë‹¹ì‹ ì€ íƒ„ì†Œë°°ì¶œê¶Œì„ ì•ˆë‚´í•˜ëŠ” ì±—ë´‡ì…ë‹ˆë‹¤. 
                ì‚¬ìš©ìì—ê²Œ ê°€ëŠ¥í•œ ë§ì€ ì •ë³´ë¥¼ ì¹œì ˆí•˜ê²Œ ì œê³µí•˜ì‹­ì‹œì˜¤.
                
                Answer the question based only on the following context:
                {context}

                Question: {question}
                """
                prompt = ChatPromptTemplate.from_template(template)

                chain = RunnableMap({
                    "context": lambda x: retriever.get_relevant_documents(x['question']),
                    "question": lambda x: x['question']
                }) | prompt | llm

                response = chain.invoke({'question': query})
                st.markdown("**ì±—ë´‡ì˜ ë‹µë³€:**")
                st.markdown(response.content)

if __name__ == "__main__":
    main()
