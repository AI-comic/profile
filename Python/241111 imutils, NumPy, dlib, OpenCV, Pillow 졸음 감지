from imutils import face_utils
import numpy as np
import imutils
import dlib
import cv2
import os
from PIL import Image, ImageFont, ImageDraw
import pygame
import threading
import time
 
#=================================================================
#눈동자 가로,세로 비율의 Moving Average 처리
#=================================================================
def calculate_average(value):
    global g_window_Size
    global g_data
 
    g_data.append(value)
    if len(g_data) > g_window_Size:
        g_data = g_data[-g_window_Size:]
   
    if len(g_data) < g_window_Size:
        return 0.0
    return float(sum(g_data) / g_window_Size)
 
#=================================================================
# 눈동자 가로, 세로 euclidean 거리 구하기
#=================================================================
def euclidean_dist(ptA, ptB):
    return np.linalg.norm(ptA - ptB)
 
# 눈의 가로, 세로 종횡비 구하기
def eye_aspect_ratio(eye):
    a = euclidean_dist(eye[1], eye[5])  # 눈의 세로
    b = euclidean_dist(eye[2], eye[4])  # 눈의 세로
    c = euclidean_dist(eye[0], eye[3])  # 눈의 가로
    ear = (a + b) / (2.0 * c)  # 종횡비
    return ear
 
#=================================================================
# 졸음 감지 시 알림 처리 (소리 재생)
#=================================================================
def alarm_notification(filename, to_number):
    start_time = 5.3  # 음악 재생 시작 시간 (초)
    duration = 10    # 재생할 시간 (초)

    pygame.init()
    pygame.mixer.init()
        
    try:
        pygame.mixer.music.load(filename)
        pygame.mixer.music.play()
        pygame.mixer.music.set_pos(start_time)
        time.sleep(duration)  # 지정된 시간 동안 대기
        pygame.mixer.music.stop()  # 음악 정지
    except Exception as e:
        print("Error:", e)
    finally:
        pygame.quit()
        

#=================================================================
#Alarm 처리 Thread 
#마지막 알람 발생 후 10초 후 알람 발생 
#=================================================================
def start_Alarm():
	global g_pre_alarm_time
	cur_time = time.time()
	
	if (cur_time - g_pre_alarm_time) > 10:
		filename = 'test.mp3'
		to_number = ''
		thread = threading.Thread(target=alarm_notification, args=(filename,to_number,))
		thread.start()
		g_pre_alarm_time = cur_time
	else:
		print("Alarm is not progress time: {0}s.".format(int(cur_time - g_pre_alarm_time)))


#=================================================================
# 초기값 설정
#=================================================================
g_pre_alarm_time = 0
g_window_Size = 30
g_data = []
g_blinkCounter = 0
 
# 실헹 경로 설정
this_program_directory = os.path.dirname(os.path.abspath(__file__))
os.chdir(this_program_directory)
 
# 한글 폰트 설정
fontpath = "C:\Windows\Fonts\Hancom Gothic Regular.ttf"
font = ImageFont.truetype(fontpath, 36)
 
#=================================================================
# 얼굴 감지, 눈동자 감지 처리
#=================================================================
# CNN 기반 얼굴 감지 모델 초기화
detector = dlib.cnn_face_detection_model_v1('mmod_human_face_detector.dat')
 
# dlib의 68점 얼굴 랜드마크 모델 로드
predictor = dlib.shape_predictor('shape_predictor_68_face_landmarks.dat')
 
# 오른쪽, 왼쪽 눈 좌표 인덱스
(lStart, lEnd) = face_utils.FACIAL_LANDMARKS_IDXS["left_eye"]
(rStart, rEnd) = face_utils.FACIAL_LANDMARKS_IDXS["right_eye"]
 
cap = cv2.VideoCapture(0)
 
if not cap.isOpened():
    print("Error: 비디오 파일을 열 수 없습니다.")
    exit()
 
time.sleep(2.0)
 
while True:
    # 웹캠 영상 읽기
    ret, frame = cap.read()
    if not ret:
        print("비디오가 끝났거나 에러가 발생했습니다.")
        break
 
    frame = imutils.resize(frame, width=720)
    frame = cv2.flip(frame, 1)
 
    # 입력 영상 grayscale 처리
    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
 
    # 얼굴 Detection
    rects = detector(gray, 1)
 
    for rect in rects:
        # CNN 모델은 결과를 'rect.rect'로 반환
        x, y, w, h = rect.rect.left(), rect.rect.top(), rect.rect.width(), rect.rect.height()
       
        # 얼굴 영역 bounding box 그리기
        cv2.rectangle(frame, (x, y), (x + w, y + h), (255, 0, 0), 2)
 
        # 눈동자 Detection(68 landmarks)
        shape = predictor(gray, rect.rect)
        shape = face_utils.shape_to_np(shape)
 
        # 왼쪽 및 오른쪽 눈 좌표를 추출하여 양쪽 눈의 종횡비 계산
        leftEye = shape[lStart:lEnd]
        rightEye = shape[rStart:rEnd]
        leftEAR = eye_aspect_ratio(leftEye)
        rightEAR = eye_aspect_ratio(rightEye)
 
        # 양쪽 눈의 종횡비 평균
        ear = (leftEAR + rightEAR) / 2.0
        ear_avg = calculate_average(ear)
 
        # 눈 종횡비율이 0.22 미만이면 깜빡임으로 판단
        if ear_avg < 0.22:
            g_blinkCounter += 1
 
            # 깜박임 회수가 40회 이상이면 졸음 감지
            if g_blinkCounter >= 40:
                img_pillow = Image.fromarray(frame)
                draw = ImageDraw.Draw(img_pillow, 'RGBA')
                draw.text((5, 10), "졸음이 감지 되었습니다", (0, 0, 255), font=font)
                frame = np.array(img_pillow)
 
                # 양쪽 눈동자 빨간 점 그리기
                cv2.circle(frame, tuple(leftEye[0]), 2, (0, 0, 255), -1)
                cv2.circle(frame, tuple(rightEye[3]), 2, (0, 0, 255), -1)
 
                start_Alarm()
        else:
            g_blinkCounter = 0
 
    # 영상 출력
    cv2.imshow("Frame", frame)
 
    key = cv2.waitKey(1) & 0xFF
    if key == ord("q"):
        break
 
cap.release()
cv2.destroyAllWindows()
